#!/usr/bin/env python
# coding: utf-8

# # Работа с NumPy

# In[34]:


import numpy as np
import pandas as pd


# ## Задание 1
# Импортируйте библиотеку Numpy и дайте ей псевдоним np.
# Создайте массив Numpy под названием a размером 5x2, то есть состоящий из 5 строк и 2 столбцов.
# Первый столбец должен содержать числа 1, 2, 3, 3, 1, а второй - числа 6, 8, 11, 10, 7. Будем считать,
# что каждый столбец - это признак, а строка - наблюдение. Затем найдите среднее значение по
# каждому признаку, используя метод mean массива Numpy. Результат запишите в массив mean_a, в
# нем должно быть 2 элемента.

# In[35]:


a = np.array([[1, 6], [2, 8], [3, 11], [3, 10], [1, 7]])
a


# In[36]:


mean_a = a.mean(axis=0)
mean_a


# ## Задание 2
# Вычислите массив a_centered, отняв от значений массива “а” средние значения соответствующих
# признаков, содержащиеся в массиве mean_a. Вычисление должно производиться в одно действие.
# Получившийся массив должен иметь размер 5x2.

# In[37]:


a_centered = a - mean_a
a_centered


# ## Задание 3
# Найдите скалярное произведение столбцов массива a_centered. В результате должна получиться
# величина a_centered_sp. Затем поделите a_centered_sp на N-1, где N - число наблюдений.

# In[38]:


a_centered_sp = a_centered[:, 0].dot(a_centered[:, 1])
a_centered_sp


# In[39]:


N = a.size/a.ndim
N
# или N = len(a) 


# ## Задание 4**
# © geekbrains.ru
# Число, которое мы получили в конце задания 3 является ковариацией двух признаков, содержащихся
# в массиве “а”. В задании 4 мы делили сумму произведений центрированных признаков на N-1, а не на
# N, поэтому полученная нами величина является несмещенной оценкой ковариации.

# In[40]:


cov = a_centered_sp / N
cov


# In[41]:


#ковариация с помощью функции cov(m)
cov_function = np.cov(np.transpose(a))
cov_function


# In[42]:


cov_function[0, 1]


# # Работа с данными в Pandas
# 

# In[43]:


import pandas as pd


# ## Задание 1
# Импортируйте библиотеку Pandas и дайте ей псевдоним pd. Создайте датафрейм authors со
# столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и
# ['Тургенев', 'Чехов', 'Островский'].
# Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно
# содержатся данные:
# [1, 1, 1, 2, 2, 3, 3],
# ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и
# поклонники'],
# [450, 300, 350, 500, 450, 370, 290].

# In[44]:


author_name = pd.DataFrame({'author_id': [1, 2, 3], 
                           'author_name': ['Тургенев', 'Чехов', 'Островский']})
author_name


# In[45]:


book = pd.DataFrame({'author_id': [1, 1, 1, 2, 2, 3, 3],
                    'book_title': ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 
                                   'Гроза', 'Таланты и поклонники'], 
                    'price': [450, 300, 350, 500, 450, 370, 290]})
book


# ## Задание 2
# Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id.
# 

# In[46]:


authors_price = pd.merge(author_name, book, on = 'author_id', how = 'outer')
authors_price


# ## Задание 3
# Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими
# книгами.

# In[47]:


top5 = authors_price.nlargest(5, 'price')
top5


# ## Задание 4
# Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat
# должны быть четыре столбца:
# author_name, min_price, max_price и mean_price,
# в которых должны содержаться соответственно имя автора, минимальная, максимальная и средняя
# цена на книги этого автора.

# In[48]:


authors_stat = authors_price['author_name'].value_counts()
authors_stat


# In[49]:


authors_stat = authors_price.groupby('author_name').agg({'price':['min', 'max', 'mean']})
authors_stat


# In[50]:


authors_stat.rename(columns = {'min': 'min_price', 'max': 'max_price', 'mean': 'mean_price',})


# ## Задание 5.
# Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться
# данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные
# из следующего списка:
# ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая'].
# Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака.Для каждого
# автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого
# функцию pd.pivot_table. При этом столбцы должны называться "твердая" и "мягкая", а индексами
# должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при
# необходимости загрузите библиотеку Numpy.
# Назовите полученный датасет book_info и сохраните его в формат pickle под названием
# "book_info.pkl". Затем загрузите из этого файла датафрейм и назовите его book_info2.
# Удостоверьтесь, что датафреймы book_info и book_info2 идентичны.

# In[51]:


authors_price['cover'] = ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']
authors_price


# In[52]:


# ?pd.pivot_table


# In[53]:


book_info = pd.pivot_table(authors_price, values='price', index = 'author_name', columns = ['cover'], aggfunc=np.sum)
book_info


# In[54]:


book_info['мягкая'].fillna(0, inplace = True)
book_info['твердая'].fillna(0, inplace = True)
book_info


# In[55]:


book_info.to_pickle('book_info.pkl')


# In[56]:


book_info2 = pd.read_pickle('book_info.pkl')
book_info2

